import { Steps } from 'nextra-theme-docs'
import { Callout } from 'nextra-theme-docs'


# Cookbook (Examples)

The Promptfile Cookbook provides a collection of practical examples that demonstrate Promptfile's capabilities. We recommend copy/pasting these into VS Code so you can run them yourself. We added comments to help you understand what's happening.

<Steps>

### **Introduction**

```prompt
Welcome to Promptfile! Promptfile is a Markdown-like file format for working with language models. To help you learn Promptfile, we'll work through a few examples together and build some LLM applications. We'll start simple by using the `gpt-3.5-turbo` model from OpenAI to generate haikus.

This prompt contains two chat blocks: a System block and a User block. The System block (`<System>`) gives initial instructions to the language model, setting the scene. The User block (`<User>`) represents the user's input or query to the language model.

If you're unfamilar with chat blocks in the context of prompting, you can learn more from docs provided by OpenAI (https://platform.openai.com/docs/guides/gpt/chat-completions-api) and Anthropic (https://console.anthropic.com/docs/prompt-design).

To start, try executing this prompt by using the `Promptfile: run in playground` command. You can find this command by opening the command palette (Cmd+Shift+P on Mac, Ctrl+Shift+P on Windows) and searching for `Promptfile`.

You can also execute this command via the keyboard shortcut Cmd+Enter (Mac) / Ctrl+Enter (Windows).


<System>
You are HaikuGPT. Always respond to the user in the form of a haiku.
</System>


Feel free to change this text to anything you want!
<User>
Tell me about the ocean.
</User>
```
### **Including variables in your template**

You can also include variables in your template using the `@{variableHere}{:prompt}`. This allows you to have a more dynamic prompt. When using your prompt in your project, you can pass these variables in as arguments.

```prompt
---
model: gpt-3.5-turbo
---

Awesome, you're well on your way to working with Promptfile! Promptfiles also support variables â€” you can establish a variable using the `@{` and `}` syntax. Let's try it out!

<System>
You are a New York Times movie critic. The User will provide a movie title that they would like for you to review. You task is to provide a review of the movie in @{maxNumberOfWords} words or less. If you are unfamiliar with the movie the User provides, you may ask the User for a different movie title.
</System>


<User>
Movie title: "@{movieTitle}"
</User>

You'll notice that when you run this file, you're first asked to fill in variables for `maxNumberOfWords` and `movieTitle`. Those values will be inserted into the prompt before the LLM is queried.
```

### **Calling functions**

Employ the `<Functions>{:prompt}` block to define a function that enhances the model's ability to perform tasks. If your function returns something, it will be wrapped inside a `<Function>{:prompt}` block. For the purposes of the demo example, we include a `testValue` that our function would return.

Please note that only `gpt-3.5-turbo-0613` and `gpt-4-0613` models have been fine-tuned to call functions.

```prompt
---
model: gpt-3.5-turbo-0613
---

<Functions>
[
  {
    "name": "calculator",
    "description": "Calculates the result of a math expression using JavaScript `eval`.",
    "parameters": {
      "type": "object",
      "properties": {
        "expression": {
          "type": "string",
          "description": "The expression to evaluate in JavaScript."
        }
      },
      "required": ["expression"]
    },
    "testValue": "1.08933674"
  }
]
</Functions>

<User>
what is 2 to the .12345 power?
</User>
```


</Steps>